{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Versions Python et Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.3\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "# import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modélisation CNN avec tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "\n",
    "# Gestion des images : lecture, transformations\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image, image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation\n",
    "\n",
    "# Gestion de l'architecture du réseau\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Conv2D, Activation, Dense, Dropout\n",
    "from tensorflow.keras.layers import MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Resizing, Rescaling, BatchNormalization\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy\n",
    "\n",
    "# Architecture de modèles de réseaux pré-entrainés (fonctionnalité de Transfer Learning)\n",
    "from tensorflow.keras.applications import MobileNetV2, VGG16\n",
    "\n",
    "# Algorithme d'optimisation\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "\n",
    "# Sauvegarde, arret\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Open CV\n",
    "import cv2\n",
    "\n",
    "# Performances des modeles\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chemin des 2 dossiers d'images par classe à prédire pour l'apprentissage et l'évaluation des performances et l'inférence\n",
    "SRC_PATH_TRAIN = \"./dataset_footprint/train/\"\n",
    "SRC_PATH_TEST = \"./dataset_footprint/test/\"\n",
    "\n",
    "# Liste des catégories (classes à prévoir)\n",
    "LST_LABELS = os.listdir(SRC_PATH_TRAIN)\n",
    "\n",
    "# Parametres pour la generation d'images\n",
    "SEED_VALUE = 42\n",
    "VALID_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 160  # Taille de l'image IMG_SIZExIMG_SIZE (on augmente la resolution de 100 a 160)\n",
    "BATCH_SIZE = 10  # nb de données à passer pour un A/R dans le réseau (total de 77 images x 3 classes)\n",
    "NB_EPOCHS = 30  # Nb de passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition comme label les noms des sous-dossiers de travail\n",
    "labels = os.listdir(SRC_PATH_TRAIN)\n",
    "LST_DIR_LABELS = labels\n",
    "LST_DIR_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du modèle optimal (nom et sous-dossier)\n",
    "CKPT_NO, MDL_NAME = 'ckpt_footprints_1', '3footprints_CNN'\n",
    "CKPT_DIR = './'+ CKPT_NO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions Locales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(history):\n",
    "    \"\"\"\n",
    "    Fonction de tracé de la courbe d'ajustement d'un modèle\n",
    "    Arguments:\n",
    "        history : sequence de recueil des métriques d'évaluation d'un modèle lors de la phase d'apprentissage\n",
    "        les métriques sont ici prédéfinies : 'accuracy','val_accuracy','loss','val_loss'\n",
    "    Returns:\n",
    "        2 figures Matplotlib superposées des métriques 'accuracy' et 'loss' sur les datasets TRAIN et VALIDATION\n",
    "    \"\"\"\n",
    "    # Définition des séquences de sauvegarde des performances en TRAIN (accuracy et loss) et VALIDATION (val_)\n",
    "    accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    # Liste des itérations de calcul : epochs\n",
    "    lst_epochs = range(len(accuracy))\n",
    "    \n",
    "    # Tracé en 2 figures\n",
    "    plt.figure(figsize=(20,6))\n",
    "    plt.plot(lst_epochs, accuracy, \"b\", label=\"accuracy [TRAIN]\")\n",
    "    plt.plot(lst_epochs, val_accuracy, \"r\", label=\"accuracy [VALIDATION]\")\n",
    "    plt.title(\"Exactitude du modèle\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(20,6))\n",
    "    plt.plot(lst_epochs, loss, \"b\", label=\"loss [TRAIN]\")\n",
    "    plt.plot(lst_epochs, val_loss, \"r\", label=\"loss [VALIDATION]\")\n",
    "    plt.title(\"Courbe de perte du modèle\")    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING THIS FUNCTION IS BASICALLY UNUSED\n",
    "\n",
    "# create a confusion matrix to visually represent incorrectly classified images\n",
    "def plot_confusion_matrix(y_true, y_pred, classes, out_path=\"\"):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    df_cm = pd.DataFrame(cm, index=[i for i in classes], columns=[i for i in classes])\n",
    "    plt.figure(figsize=(3,3))\n",
    "    ax = sns.heatmap(df_cm, annot=True, square=True, fmt=\"d\", linewidths=.2, cbar_kws={\"shrink\": 0.8})\n",
    "    if out_path:\n",
    "        plt.savefig(out_path + \"/confusion_matrix.png\")  # as in the plot_model_history, the matrix is saved in a file called \"model_name_confusion_matrix.png\"\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition de l'architecture du réseau de neurones convolutifs (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model():\n",
    "    # Initialisation du réseau\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Blocs de Convolution\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3), padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "   \n",
    "    model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    # Couches de classification\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    #model.add(Dense(16, activation='relu'))\n",
    "    #model.add(Dropout(0.3))\n",
    "    \n",
    "    # Couche de sortie\n",
    "    model.add(Dense(len(LST_LABELS), activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'inférence avec le modele model de l'image n° numero du dossier src_path de la classe categorie\n",
    "def f_footprint_predict(categorie, numero, model, src_path=SRC_PATH_TEST, lst_labels=LST_LABELS):\n",
    "    # Image à classifier dans la catégorie courante\n",
    "    id_image = categorie + '_' + numero + '.jpg'\n",
    "    lb_image = src_path + '/' + categorie + '/' + id_image\n",
    "    print('Image :', lb_image)\n",
    "\n",
    "    # Lecture et normalisation de l'image\n",
    "    img = load_img(lb_image, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "    img_array = img_to_array(img, dtype=np.uint8)\n",
    "    img_array = np.array(img_array)/255.0\n",
    "    img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "    # Affichage\n",
    "    img = cv2.imread(lb_image)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    print(plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)))\n",
    "    plt.show()\n",
    "\n",
    "    # Prédiction et évaluation\n",
    "    predictions = model.predict(img_array)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "    # Affichage des résultats\n",
    "    print(\"Cette image appartient probablement à la classe {} avec un niveau de confiance à {:.2f}.\"\n",
    "        .format(lst_labels[np.argmax(score)], 100 * np.max(score)))\n",
    "\n",
    "    print(tf.nn.softmax(predictions).numpy())\n",
    "    return predictions, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_layer_trainable(model):\n",
    "    ''' Statut et nom des couches d'un modèle\n",
    "    '''\n",
    "    for layer in model.layers:\n",
    "        print(\"{0}:\\t{1}\".format(layer.trainable, layer.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction du modèle et apprentissage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epsiEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
